{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90325ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63ef8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'sp500_data.db'\n",
    "engine = sqlite3.connect(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cde738d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns loaded: (391, 503)\n",
      "Date range: 2024-03-28 to 2025-10-17\n"
     ]
    }
   ],
   "source": [
    "returns = pd.read_sql(\"SELECT * FROM returns\", engine, index_col='Date', parse_dates=['Date'])\n",
    "print(f\"Returns loaded: {returns.shape}\")\n",
    "print(f\"Date range: {returns.index[0].date()} to {returns.index[-1].date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "291ada0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P 500 returns loaded: (751, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sp500_returns = pd.read_sql(\"SELECT * FROM sp500_returns\", engine, index_col='Date', parse_dates=['Date'])\n",
    "print(f\"S&P 500 returns loaded: {sp500_returns.shape}\\n\")\n",
    "\n",
    "engine.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6476410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = returns.corr()\n",
    "distance_matrix = 1 - correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15131587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 126253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "condensed_dist = squareform(distance_matrix.values)\n",
    "print(f\"length {len(condensed_dist)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0afcfe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cluster 1:   7 stocks (1.4%)\n",
      "  Cluster 2: 489 stocks (97.2%)\n",
      "  Cluster 3:   2 stocks (0.4%)\n",
      "  Cluster 4:   4 stocks (0.8%)\n",
      "  Cluster 5:   1 stocks (0.2%)\n",
      "----------------------------------------\n",
      "  Total: 503 stocks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Z = linkage(condensed_dist, method='average')\n",
    "\n",
    "# Cut dendrogram to get 5 clusters\n",
    "n_clusters = 5\n",
    "cluster_labels = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "\n",
    "# Check cluster sizes\n",
    "cluster_sizes = pd.Series(cluster_labels).value_counts().sort_index()\n",
    "for cluster_id, size in cluster_sizes.items():\n",
    "    print(f\"  Cluster {cluster_id}: {size:3d} stocks ({size/len(cluster_labels)*100:.1f}%)\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  Total: {len(cluster_labels)} stocks\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fdc13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating equally weighted portfolios for each cluster...\n"
     ]
    }
   ],
   "source": [
    "# Create 5 equally weighted portfolios\n",
    "print(\"Creating equally weighted portfolios for each cluster...\")\n",
    "portfolio_returns_dict = {}\n",
    "\n",
    "for cluster_id in range(1, n_clusters + 1):\n",
    "    # Get stocks in this cluster\n",
    "    cluster_mask = cluster_labels == cluster_id\n",
    "    cluster_stocks = returns.columns[cluster_mask].tolist()\n",
    "    \n",
    "    # Calculate equally weighted portfolio returns\n",
    "    cluster_portfolio = returns[cluster_stocks].mean(axis=1)\n",
    "    portfolio_returns_dict[f'Portfolio_{cluster_id}'] = cluster_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4242e801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Portfolio returns DataFrame created: (391, 5)\n",
      "Date range: 2024-03-28 to 2025-10-17\n",
      "\n",
      "Portfolio returns summary:\n",
      "       Portfolio_1  Portfolio_2  Portfolio_3  Portfolio_4  Portfolio_5\n",
      "count   391.000000   391.000000   391.000000   391.000000   391.000000\n",
      "mean     -0.000581     0.000520    -0.000448     0.000445     0.001164\n",
      "std       0.017880     0.010213     0.023210     0.010254     0.012218\n",
      "min      -0.130694    -0.057503    -0.211917    -0.051042    -0.025229\n",
      "25%      -0.008049    -0.003854    -0.010421    -0.004678    -0.001835\n",
      "50%       0.000153     0.000325    -0.000699     0.000906     0.000124\n",
      "75%       0.008845     0.006070     0.010344     0.005648     0.001996\n",
      "max       0.049030     0.085946     0.109273     0.045552     0.162274\n"
     ]
    }
   ],
   "source": [
    "portfolio_returns = pd.DataFrame(portfolio_returns_dict)\n",
    "\n",
    "print(f\"\\nPortfolio returns DataFrame created: {portfolio_returns.shape}\")\n",
    "print(f\"Date range: {portfolio_returns.index[0].date()} to {portfolio_returns.index[-1].date()}\")\n",
    "print(\"\\nPortfolio returns summary:\")\n",
    "print(portfolio_returns.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43d2e9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Portfolio_1  Portfolio_2  Portfolio_3  Portfolio_4  Portfolio_5\n",
      "Portfolio_1     0.080561     0.011309     0.007905     0.008282     0.001263\n",
      "Portfolio_2     0.011309     0.026283     0.010692     0.002217    -0.000284\n",
      "Portfolio_3     0.007905     0.010692     0.135756     0.009531     0.000078\n",
      "Portfolio_4     0.008282     0.002217     0.009531     0.026497     0.003884\n",
      "Portfolio_5     0.001263    -0.000284     0.000078     0.003884     0.037622\n"
     ]
    }
   ],
   "source": [
    "mu = portfolio_returns.mean() * 252  # 252 trading days per year\n",
    "cov_matrix = portfolio_returns.cov() * 252\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "666f8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk-free rate (assume 3% annually)\n",
    "rf = 0.03\n",
    "def negative_sharpe(weights, mu, cov_matrix, rf):\n",
    "    portfolio_return = np.dot(weights, mu)\n",
    "    portfolio_variance = np.dot(weights, np.dot(cov_matrix, weights))\n",
    "    portfolio_std = np.sqrt(portfolio_variance)\n",
    "    \n",
    "    if portfolio_std == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    sharpe_ratio = (portfolio_return - rf) / portfolio_std\n",
    "    return -sharpe_ratio\n",
    "\n",
    "# Constraints: weights sum to 1\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "\n",
    "# Bounds: 0 <= weight <= 1 (no short selling)\n",
    "bounds = tuple((0, 1) for _ in range(len(mu)))\n",
    "\n",
    "# Initial guess: equal weights\n",
    "w0 = np.array([1/len(mu)] * len(mu))\n",
    "\n",
    "# Optimize\n",
    "result = minimize(negative_sharpe, w0, args=(mu, cov_matrix, rf),\n",
    "                  method='SLSQP', bounds=bounds, constraints=constraints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e09c187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weights = result.x\n",
    "optimal_sharpe = -result.fun\n",
    "optimal_return = np.dot(optimal_weights, mu)\n",
    "optimal_variance = np.dot(optimal_weights, np.dot(cov_matrix, optimal_weights))\n",
    "optimal_std = np.sqrt(optimal_variance)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
